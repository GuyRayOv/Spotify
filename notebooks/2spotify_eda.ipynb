{"cells":[{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"FDg4TZW6rZ90"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"43FuYnhY8kLz"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sb\n","import warnings\n","from google.colab import files\n","import pickle\n","import os\n","\n","!pip install scipy\n","import scipy.stats as stats\n","\n","!pip install papermill\n","!pip install nbconvert\n","!pip install nbformat\n","!pip install IPython\n","\n","import papermill as pm\n","import nbformat\n","from nbconvert import HTMLExporter\n","from IPython.display import HTML, display\n","\n","import json\n","from google.colab import drive\n","\n","warnings.filterwarnings(\"ignore\")\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6g2gBwgKEV65"},"outputs":[],"source":["BG_BLACK = \"\\033[40m\"\n","BG_RED = \"\\033[41m\"\n","BG_GREEN = \"\\033[42m\"\n","BG_YELLOW = \"\\033[43m\"\n","BG_BLUE = \"\\033[44m\"\n","BG_MAGENTA = \"\\033[45m\"\n","BG_CYAN = \"\\033[46m\"\n","BG_WHITE = \"\\033[47m\"\n","BG_DARK_GRAY = \"\\033[100m\"\n","BG_BRIGHT_RED = \"\\033[101m\"\n","BG_BRIGHT_GREEN = \"\\033[102m\"\n","BG_BRIGHT_YELLOW = \"\\033[103m\"\n","BG_BRIGHT_BLUE = \"\\033[104m\"\n","BG_BRIGHT_MAGENTA = \"\\033[105m\"\n","BG_BRIGHT_CYAN = \"\\033[106m\"\n","BG_WHITE = \"\\033[107m\"\n","RESET = \"\\033[0m\" # Reset all formatting"]},{"cell_type":"markdown","source":["# Mount drive, Load config"],"metadata":{"id":"7ApsCkmBrjAr"}},{"cell_type":"code","source":["PROJECT_PATH = '/content/drive/MyDrive/Projects/GitHub/Spotify/'\n","CONFIG_FILE = f\"{PROJECT_PATH}src/config.json\""],"metadata":{"id":"lpAUqrlzOSjQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["drive.mount('/content/drive')\n","\n","with open(CONFIG_FILE, 'r') as f:\n","    project_config = json.load(f)\n","    project_config.pop('_comment', None)\n","    project_config.pop('_note', None)\n","    f.close()"],"metadata":{"id":"jsWS0uXZwymE"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4TskHCsOkFwY"},"outputs":[],"source":["np.random.seed(31071967)"]},{"cell_type":"markdown","source":["# Run project notebook N-1"],"metadata":{"id":"I0nHCI28roho"}},{"cell_type":"code","source":["if project_config['chain_notebooks'] == '1':\n","\n","  input_file = f\"{project_config['project_path']}{project_config['notebooks_directory']}{project_config['notebook1']}\"\n","  output_file = f\"{project_config['project_path']}{project_config['output_directory']}{project_config['output1']}\"\n","\n","  # --- Execute the proviuse notebook with parameters ---\n","  pm.execute_notebook(\n","      input_path = input_file,\n","      output_path = output_file,\n","      log_output=False,  # don't print logs while running\n","      progress_bar=True\n","  )\n","\n","  # --- Convert the executed notebook to HTML ---\n","  nb = nbformat.read(output_file, as_version=4)\n","  html_exporter = HTMLExporter()\n","  html_exporter.template_name = \"lab\"  # modern look; alternatives: 'classic', 'basic'\n","  body, _ = html_exporter.from_notebook_node(nb)\n","\n","  # --- Display the HTML result inline ---\n","  display(HTML(body))"],"metadata":{"id":"YY6gc_3UZbUo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"28TEekNx_AKO"},"source":["# Load pickle"]},{"cell_type":"code","source":["pickle_file      = project_config['project_path'] + project_config['pickles_directory'] + project_config['pickle1']\n","test_pickle_file = project_config['project_path'] + project_config['pickles_directory'] + project_config['pickle1_test']"],"metadata":{"id":"qbNQzPjJPel9"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wtHz_WPD7yF_"},"outputs":[],"source":["# Read pickle into DataFrame\n","df = pd.read_pickle(pickle_file)\n","\n","display(df.head(1)), display(df.tail(1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0VQAHD-I9Jxx"},"outputs":[],"source":["# types of cols\n","small_cat_cols     = ['mode_mean_popularity','key_mean_popularity', 'playlist_genre_grouped_mean_popularity','release_decade_mean_popularity','release_month_mean_popularity']\n","small_cat_symboles = ['mode','key','playlist_genre_grouped','release_decade','release_month', 'release_year']\n","large_cat_cols     = ['track_artist_mean_popularity','track_album_id_mean_popularity','playlist_id_mean_popularity']\n","cont_cols          = ['acousticness', 'danceability','duration_ms','energy', 'liveness', 'loudness', 'speechiness', 'tempo','valence']\n","y_col              = 'track_popularity'\n","x_cols             = large_cat_cols + small_cat_cols + cont_cols\n","MERGE_ON_COL       = 'track_id'"]},{"cell_type":"markdown","metadata":{"id":"9DS8SF_eXH9B"},"source":["# Skewness, Boxplots"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GP2nxlt3T4sl"},"outputs":[],"source":["# Reset counts before applying the function\n","normal_distributions = 0\n","other_distributions = 0\n","\n","def highlight_distribution_type(cell_value):\n","\n","    highlight = 'background-color: mediumspringgreen;'\n","    default = ''\n","    negative = 'background-color: hotpink;'\n","\n","    global normal_distributions, other_distributions\n","\n","    if cell_value > 1:\n","        other_distributions += 1\n","        return highlight\n","    elif cell_value < -1:\n","        other_distributions += 1\n","        return negative\n","    else:\n","        normal_distributions += 1\n","        return default\n","\n","display( pd.DataFrame(df[[y_col]+x_cols].skew(),columns=['skewness']).sort_values(by='skewness', ascending=False).style.applymap(highlight_distribution_type) )\n","\n","print(f'Normal distributions: {normal_distributions}')\n","print(f'Other distributions: {other_distributions}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QNP3ZeGmmgKy"},"outputs":[],"source":["## boxplots\n","cols_to_plot = [y_col] + large_cat_cols + small_cat_cols + cont_cols\n","\n","plt.figure(figsize=(20,200))\n","for plot_counter, col in enumerate(cols_to_plot, start=1):\n","  ax = plt.subplot(60, 3, plot_counter)\n","  sb.boxplot(data=df, x=col, ax=ax)\n","  plt.subplots_adjust(hspace = 0.7)\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"zY6ZtJmzaivt"},"source":["\n","\n","# Correlations, Pairpolts\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ei4rfTIQ8dyu"},"outputs":[],"source":["# calculating highest and lowest correlations\n","corr = df[large_cat_cols + cont_cols + [y_col]].corr() #(method='spearman')\n","\n","# Unstack into pairs\n","corr_pairs = corr.unstack()\n","\n","# Drop self-correlations\n","corr_pairs = corr_pairs[corr_pairs.index.get_level_values(0) != corr_pairs.index.get_level_values(1)]\n","\n","# Sort by correlation value\n","sorted_corr = corr_pairs.sort_values(ascending=False)\n","\n","print()\n","print(f\"{BG_BRIGHT_RED} Highest positive correlations{RESET}\")\n","print(sorted_corr.head(20)[::2])\n","print()\n","print(f\"{BG_BRIGHT_BLUE} Highest Negative correlations{RESET}\")\n","print(sorted_corr.tail(20)[-1::-2])\n","\n","sb.heatmap(corr, cbar = True,  square=True, annot=True, annot_kws={'size': 6}, fmt=\".2f\", cmap= 'coolwarm')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XeKbbsPfZBur"},"outputs":[],"source":["pair_plots = [large_cat_cols+[y_col], cont_cols+[y_col]]\n","\n","for plot in pair_plots:\n","  pp = sb.pairplot(df, vars=plot, height=3, aspect=1.1)\n","  pp.fig.subplots_adjust(wspace=0.15, hspace=0.15)\n","  plt.show()"]},{"cell_type":"markdown","metadata":{"id":"JDUfwgB2kcKP"},"source":["# Anova"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SdA0DlONkf_K"},"outputs":[],"source":["def show_anova(*samples, names=None, groups_title=None):\n","\n","  if names is None: names = [f\"Sample {i+1}\" for i in range(len(samples))]\n","  if groups_title is None: groups_title = 'groups'\n","\n","  # Run ANOVA\n","  f_stat, p_val = stats.f_oneway(*samples)\n","\n","  if (p_val < 0.05): print(f\"{BG_BRIGHT_RED}There is a significant difference between {groups_title}{RESET}\")\n","  else: print(f\"{BG_BRIGHT_GREEN}No significant difference between {groups_title}{RESET}\")\n","\n","  # Summary table\n","  summary = pd.DataFrame({\n","      \"Group\": names,\n","      \"Mean\": [pd.Series(s).mean() for s in samples],\n","      \"Variance\": [pd.Series(s).var() for s in samples],\n","      \"N\": [len(s) for s in samples]\n","    })\n","\n","  print(\"\\nSummary Table\")\n","  print(\"-------------\")\n","  print(summary)\n","  print()\n","  print(\"ANOVA Results\")\n","  print(\"-------------\")\n","  print(f\"F-statistic: {f_stat:.4f}\")\n","  print(f\"p-value:     {p_val:.4e}\\n\")\n","\n","\n","  plt.figure(figsize=(8, 4))\n","\n","  # Plot the density of each group\n","  for i in range(len(samples)):\n","    sb.histplot(samples[i], kde=True, label=names[i], color=f'C{i}', bins=20, stat=\"density\", alpha=0.5)\n","    plt.axvline(np.mean(samples[i]), color=f'C{i}', linestyle='--', linewidth=1)\n","\n","  plt.ylabel('Density', fontsize=12)\n","  plt.legend(fontsize=10)\n","  plt.xticks(fontsize=10)\n","  plt.yticks(fontsize=10)\n","  plt.grid(False)\n","\n","  plt.show()\n","\n","  return"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6J39AMV3f-Z2"},"outputs":[],"source":["print('\\n\\n################################ ANOVA on popularity between groups with very large categories #################################\\n')\n","\n","popularity_groups = large_cat_cols + [y_col]\n","sample_size = 1000\n","\n","samples = [df[col].sample(sample_size) for col in popularity_groups]\n","\n","show_anova(*samples,\n","           names=popularity_groups,\n","           groups_title='popularity of groups with very large categories')\n","\n","# Melt into long format for seaborn\n","df_melt = df.melt(value_vars=popularity_groups, var_name='Popularity Type', value_name='Popularity')\n","plt.figure(figsize=(8,6))\n","sb.boxplot(x='Popularity Type', y='Popularity', data=df_melt)\n","plt.xticks(rotation=75)\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0zZ_D5_QC3L4"},"outputs":[],"source":["for col in small_cat_symboles:\n","\n","  print(f'\\n\\n\\n########################## ANOVA between popularity of categories in {col} #############################\\n')\n","\n","  sample_size = 1000\n","  groups_names = list(df[col].value_counts().index)\n","\n","  # Filter out groups with fewer than sample_size records\n","  valid_groups = [name for name in groups_names if len(df[df[col]==name]['track_popularity']) >= sample_size]\n","\n","  # Create a list of samples for ANOVA from valid groups\n","  samples = [df[df[col]==name]['track_popularity'].sample(sample_size) for name in valid_groups]\n","\n","  show_anova(*samples, names=valid_groups, groups_title=f\"categories of {col}\")\n","\n","  plt.figure(figsize=(8,6))\n","  sb.boxplot(x=col, y='track_popularity', data=df)\n","  plt.xticks(rotation=90)\n","  plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ISSHfn5G5CI"},"outputs":[],"source":["sample_size = 1000\n","n_bins = 10\n","bin_labels = [f\"bin{i}\" for i in range(n_bins)]\n","\n","for col in cont_cols:\n","  print(f'\\n\\n####################### ANOVA between popularity of {n_bins} bins of {col} ##############################\\n')\n","\n","  df[f\"{col}_bins\"] = pd.qcut(df[col], q=n_bins, labels=bin_labels)\n","\n","  samples = [df[df[f\"{col}_bins\"]==label]['track_popularity'].sample(sample_size) for label in bin_labels]\n","\n","  show_anova(*samples, names=bin_labels, groups_title=f\"{col} bins\")\n","\n","  plt.figure(figsize=(8,6))\n","  sb.boxplot(x=f\"{col}_bins\", y='track_popularity', data=df)\n","  plt.show()\n","\n","  df.drop(columns=[f\"{col}_bins\"], inplace=True)"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMoEyLLZ4XCYAkdxteK++O6"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}